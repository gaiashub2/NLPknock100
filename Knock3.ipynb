{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第3章: 正規表現 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wikipediaの記事を以下のフォーマットで書き出したファイル[jawiki-country.json.gz](http://www.cl.ecei.tohoku.ac.jp/nlp100/data/jawiki-country.json.gz)がある．\n",
    "\n",
    "- 1行に1記事の情報がJSON形式で格納される\n",
    "- 各行には記事名が\"title\"キーに，記事本文が\"text\"キーの辞書オブジェクトに格納され，そのオブジェクトがJSON形式で書き出される\n",
    "- ファイル全体はgzipで圧縮される\n",
    "\n",
    "以下の処理を行うプログラムを作成せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考（pythonでの正規表現の扱い：reモジュール）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "詳しくは、[http://docs.python.jp/3/library/re.html#module-re](http://docs.python.jp/3/library/re.html#module-re)を参照"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. JSONデータの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wikipedia記事のJSONファイルを読み込み，「イギリス」に関する記事本文を表示せよ．問題21-29では，ここで抽出した記事本文に対して実行せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget http://www.cl.ecei.tohoku.ac.jp/nlp100/data/jawiki-country.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "gzip -d jawiki-country.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "head jawiki-country.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"jawiki-country.json\") as datafile:\n",
    "    for line in datafile:\n",
    "        json_data = json.loads(line)\n",
    "        #print(json_data[\"title\"])\n",
    "        if json_data[\"title\"] == \"イギリス\":\n",
    "            #print(\"hoge!!!\")\n",
    "            print(json_data[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### qiitaの答え\n",
    "```\n",
    "# coding: utf-8\n",
    "import gzip\n",
    "import json\n",
    "fname = 'jawiki-country.json.gz'\n",
    "\n",
    "with gzip.open(fname, 'rt') as data_file:\n",
    "    for line in data_file:\n",
    "        data_json = json.loads(line)\n",
    "        if data_json['title'] == 'イギリス':\n",
    "            print(data_json['text'])\n",
    "            break\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21. カテゴリ名を含む行を抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "記事中でカテゴリ名を宣言している行を抽出せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def getEnglandJson():\n",
    "    with open(\"jawiki-country.json\") as datafile:\n",
    "        for line in datafile:\n",
    "            json_data = json.loads(line)\n",
    "            if json_data[\"title\"] == \"イギリス\":\n",
    "                return json_data[\"text\"]\n",
    "\n",
    "#print(getEnglandJson())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "row_list21 = getEnglandJson().split(\"\\n\")\n",
    "print(len(row_list21))\n",
    "for row in row_list21:\n",
    "    if row[0:11] == \"[[Category:\":\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### qiitaの答え\n",
    "```\n",
    "# coding: utf-8\n",
    "import gzip\n",
    "import json\n",
    "import re\n",
    "fname = 'jawiki-country.json.gz'\n",
    "\n",
    "\n",
    "def extract_UK():\n",
    "    '''イギリスに関する記事本文を取得\n",
    "\n",
    "    戻り値：\n",
    "    イギリスの記事本文\n",
    "    '''\n",
    "\n",
    "    with gzip.open(fname, 'rt') as data_file:\n",
    "        for line in data_file:\n",
    "            data_json = json.loads(line)\n",
    "            if data_json['title'] == 'イギリス':\n",
    "                return data_json['text']\n",
    "\n",
    "    raise ValueError('イギリスの記事が見つからない')\n",
    "\n",
    "\n",
    "# 正規表現のコンパイル\n",
    "pattern = re.compile(r'''\n",
    "    ^   # 行頭\n",
    "    (   # キャプチャ対象のグループ開始\n",
    "    .*  # 任意の文字0文字以上\n",
    "    \\[\\[Category:\n",
    "    .*  # 任意の文字0文字以上\n",
    "    \\]\\]\n",
    "    .*  # 任意の文字0文字以上\n",
    "    )   # グループ終了\n",
    "    $   # 行末\n",
    "    ''', re.MULTILINE + re.VERBOSE)\n",
    "\n",
    "# 抽出\n",
    "result = pattern.findall(extract_UK())\n",
    "\n",
    "# 結果表示\n",
    "for line in result:\n",
    "    print(line)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22. カテゴリ名の抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "記事のカテゴリ名を（行単位ではなく名前で）抽出せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#pattern22 = re.compile(r'^.*\\[\\[Category:(.*)\\]\\].*$', re.MULTILINE + re.VERBOSE)\n",
    "pattern22 = re.compile(r'^.*\\[\\[Category:(.*?)(?:\\|.*)?\\]\\].*$', re.MULTILINE + re.VERBOSE)\n",
    "result22 = pattern22.findall(getEnglandJson())\n",
    "\n",
    "for line in result22:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### qiitaの答え\n",
    "```\n",
    "# 正規表現のコンパイル\n",
    "pattern = re.compile(r'''\n",
    "    ^       # 行頭\n",
    "    .*      # 任意の文字0文字以上\n",
    "    \\[\\[Category:\n",
    "    (       # キャプチャ対象のグループ開始\n",
    "    .*?     # 任意の文字0文字以上、非貪欲マッチ（貪欲にすると後半の'|'で始まる装飾を巻き込んでしまう）\n",
    "    )       # グループ終了\n",
    "    (?:     # キャプチャ対象外のグループ開始\n",
    "    \\|.*    # '|'に続く0文字以上\n",
    "    )?      # グループ終了、0か1回の出現\n",
    "    \\]\\]\n",
    "    .*      # 任意の文字0文字以上\n",
    "    $       # 行末\n",
    "    ''', re.MULTILINE + re.VERBOSE)\n",
    "\n",
    "# 抽出\n",
    "result = pattern.findall(extract_UK())\n",
    "\n",
    "# 結果表示\n",
    "for line in result:\n",
    "    print(line)\n",
    "```\n",
    "\n",
    "###### または\n",
    "\n",
    "```\n",
    "# 正規表現のコンパイル その2\n",
    "pattern = re.compile(r'''\n",
    "    ^       # 行頭\n",
    "    .*      # 任意の文字0文字以上\n",
    "    \\[\\[Category:\n",
    "    (.*?)   # キャプチャ対象、任意の文字0文字以上、非貪欲マッチ\n",
    "    (?:\\]\\]|\\|) # キャプチャ対象外、']]'または'|'\n",
    "    .*      # 任意の文字0文字以上\n",
    "    $       # 行末\n",
    "    ''', re.MULTILINE + re.VERBOSE)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23. セクション構造"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "記事中に含まれるセクション名とそのレベル（例えば\"== セクション名 ==\"なら1）を表示せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "pattern23 = re.compile(r'^(==+.+==+).*$', re.MULTILINE + re.VERBOSE)\n",
    "result23 = pattern23.findall(getEnglandJson())\n",
    "\n",
    "for line in result23:\n",
    "    temp = line[1:]\n",
    "    level = 0\n",
    "    while temp[0] == \"=\":\n",
    "        level += 1\n",
    "        temp = temp[1:]\n",
    "    print(line, level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 正規表現のコンパイル\n",
    "pattern = re.compile(r'''\n",
    "    ^       # 行頭\n",
    "    (={2,}) # キャプチャ対象、2個以上の'='\n",
    "    \\s*     # 余分な0個以上の空白（'哲学'や'婚姻'の前後に余分な空白があるので除去）\n",
    "    (.+?)   # キャプチャ対象、任意の文字が1文字以上、非貪欲（以降の条件の巻き込み防止）\n",
    "    \\s*     # 余分な0個以上の空白\n",
    "    \\1      # 後方参照、1番目のキャプチャ対象と同じ内容\n",
    "    .*      # 任意の文字が0文字以上\n",
    "    $       # 行末\n",
    "    ''', re.MULTILINE + re.VERBOSE)\n",
    "\n",
    "# 抽出\n",
    "result = pattern.findall(getEnglandJson())\n",
    "\n",
    "# 結果表示\n",
    "for line in result:\n",
    "    level = len(line[0]) - 1    # '='の数-1\n",
    "    print('{indent}{sect}({level})'.format(\n",
    "        indent='\\t' * (level - 1), sect=line[1], level=level))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### qiitaの答え\n",
    "```\n",
    "# 正規表現のコンパイル\n",
    "pattern = re.compile(r'''\n",
    "    ^       # 行頭\n",
    "    (={2,}) # キャプチャ対象、2個以上の'='\n",
    "    \\s*     # 余分な0個以上の空白（'哲学'や'婚姻'の前後に余分な空白があるので除去）\n",
    "    (.+?)   # キャプチャ対象、任意の文字が1文字以上、非貪欲（以降の条件の巻き込み防止）\n",
    "    \\s*     # 余分な0個以上の空白\n",
    "    \\1      # 後方参照、1番目のキャプチャ対象と同じ内容\n",
    "    .*      # 任意の文字が0文字以上\n",
    "    $       # 行末\n",
    "    ''', re.MULTILINE + re.VERBOSE)\n",
    "\n",
    "# 抽出\n",
    "result = pattern.findall(extract_UK())\n",
    "\n",
    "# 結果表示\n",
    "for line in result:\n",
    "    level = len(line[0]) - 1    # '='の数-1\n",
    "    print('{indent}{sect}({level})'.format(\n",
    "        indent='\\t' * (level - 1), sect=line[1], level=level))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24. ファイル参照の抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "記事から参照されているメディアファイルをすべて抜き出せ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(getEnglandJson())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "pattern24 = re.compile(r'.*(?:File|ファイル):(.+?)\\|.*', re.MULTILINE + re.VERBOSE)\n",
    "result24 = pattern24.findall(getEnglandJson())\n",
    "\n",
    "for line in result24:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### qiitaの答え\n",
    "```\n",
    "# 正規表現のコンパイル\n",
    "pattern = re.compile(r'''\n",
    "    (?:File|ファイル)   # 非キャプチャ、'File'か'ファイル'\n",
    "    :\n",
    "    (.+?)   # キャプチャ対象、任意の文字1文字以上、非貪欲\n",
    "    \\|\n",
    "    ''', re.VERBOSE)\n",
    "\n",
    "# 抽出\n",
    "result = pattern.findall(extract_UK())\n",
    "\n",
    "# 結果表示\n",
    "for line in result:\n",
    "    print(line)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 25. テンプレートの抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "記事中に含まれる「基礎情報」テンプレートのフィールド名と値を抽出し，辞書オブジェクトとして格納せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(getEnglandJson())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "pattern25 = re.compile(r'^.*(\\{\\{基礎情報.*\\n\\}\\})$', re.DOTALL + re.MULTILINE)\n",
    "\n",
    "kiso_joho = pattern25.findall(getEnglandJson())\n",
    "\n",
    "#print(type(kiso_joho[0]))\n",
    "#print(kiso_joho[0])\n",
    "\n",
    "\n",
    "'''\n",
    "rows = kiso_joho[0].split(\"\\n\")\n",
    "\n",
    "kiso_dict = {}\n",
    "\n",
    "for row in rows:\n",
    "    pattern = re.compile(\"\\|(.+?)\\s*=\\s*(.+?)\")\n",
    "    result = pattern.findall(row)\n",
    "    if len(result) > 0:\n",
    "        kiso_dict[result[0][0]] = result[0][1]\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "for item in kiso_dict.items():\n",
    "    print(item[0], \": \", item[1])\n",
    "'''\n",
    "\n",
    "pattern25b = re.compile(\"^\\|(.+?)\\s*=\\s*(.+?)(?:(?=\\n\\|)|(?=\\n$))\", re.DOTALL + re.MULTILINE)\n",
    "fields = pattern25b.findall(kiso_joho[0])\n",
    "\n",
    "kiso_dict = {}\n",
    "for field in fields:\n",
    "    kiso_dict[field[0]] = field[1]\n",
    "    \n",
    "for item in kiso_dict.items():\n",
    "    print(item[0], \": \", item[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### qiitaの答え\n",
    "```\n",
    "# 基礎情報テンプレートの抽出条件のコンパイル\n",
    "pattern = re.compile(r'''\n",
    "    ^\\{\\{基礎情報.*?$   # '{{基礎情報'で始まる行\n",
    "    (.*?)       # キャプチャ対象、任意の0文字以上、非貪欲\n",
    "    ^\\}\\}$      # '}}'の行\n",
    "    ''', re.MULTILINE + re.VERBOSE + re.DOTALL)\n",
    "\n",
    "# 基礎情報テンプレートの抽出\n",
    "contents = pattern.findall(extract_UK())\n",
    "\n",
    "# 抽出結果からのフィールド名と値の抽出条件コンパイル\n",
    "pattern = re.compile(r'''\n",
    "    ^\\|         # '|'で始まる行\n",
    "    (.+?)       # キャプチャ対象（フィールド名）、任意の1文字以上、非貪欲\n",
    "    \\s*         # 空白文字0文字以上\n",
    "    =\n",
    "    \\s*         # 空白文字0文字以上\n",
    "    (.+?)       # キャプチャ対象（値）、任意の1文字以上、非貪欲\n",
    "    (?:         # キャプチャ対象外のグループ開始\n",
    "        (?=\\n\\|)    # 改行+'|'の手前（肯定の先読み）\n",
    "        | (?=\\n$)   # または、改行+終端の手前（肯定の先読み）\n",
    "    )           # グループ終了\n",
    "    ''', re.MULTILINE + re.VERBOSE + re.DOTALL)\n",
    "\n",
    "# フィールド名と値の抽出\n",
    "fields = pattern.findall(contents[0])\n",
    "\n",
    "# 辞書にセット\n",
    "result = {}\n",
    "keys_test = []      # 確認用の出現順フィールド名リスト\n",
    "for field in fields:\n",
    "    result[field[0]] = field[1]\n",
    "    keys_test.append(field[0])\n",
    "\n",
    "# 確認のため表示（確認しやすいようにkeys_testを使ってフィールド名の出現順にソート）\n",
    "for item in sorted(result.items(),\n",
    "        key=lambda field: keys_test.index(field[0])):\n",
    "    print(item)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 26. 強調マークアップの除去"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25の処理時に，テンプレートの値からMediaWikiの強調マークアップ（弱い強調，強調，強い強調のすべて）を除去してテキストに変換せよ（参考: [マークアップ早見表](http://ja.wikipedia.org/wiki/Help:%E6%97%A9%E8%A6%8B%E8%A1%A8)）．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_markup(word):\n",
    "    pattern = re.compile(r'(\\'{2,5})(.*?)(\\1)', re.MULTILINE)\n",
    "    return pattern.sub(r'\\2', word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/labuser/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-98c7fc936fd7>\", line 13, in <module>\n",
      "    kiso_dict[field[0]] = remove_markup(field[1])\n",
      "  File \"<ipython-input-3-2cae7c362411>\", line 2, in remove_markup\n",
      "    pattern = re.compile(r'(\\'{2,5})(.*?)(\\1)', re.MULTILINE)\n",
      "TypeError: '_sre.SRE_Pattern' object is not callable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/labuser/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1821, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/labuser/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/labuser/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/labuser/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/labuser/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/labuser/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/inspect.py\", line 1415, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/Users/labuser/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 223, in findsource\n",
      "    pat = re.compile(r'^(\\s*def\\s)|(.*(?<!\\w)lambda(:|\\s))|^(\\s*@)')\n",
      "TypeError: '_sre.SRE_Pattern' object is not callable\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'_sre.SRE_Pattern' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "#pattern26 = re.compile(r'^\\{\\{基礎情報.*?$(.*?)^\\}\\}$', re.MULTILINE + re.DOTALL)\n",
    "pattern26 = re.compile(r'^.*(\\{\\{基礎情報.*\\n\\}\\})$', re.DOTALL + re.MULTILINE)\n",
    "contents26 = pattern26.findall(getEnglandJson())\n",
    "\n",
    "pattern26b = re.compile = re.compile(r'^\\|(.+?)\\s*=\\s*(.+?)(?:(?=\\n\\|)|(?=\\n$))', re.MULTILINE + re.DOTALL)\n",
    "fields = pattern26b.findall(contents26[0])\n",
    "\n",
    "kiso_dict = {}\n",
    "for field in fields:\n",
    "    kiso_dict[field[0]] = remove_markup(field[1])\n",
    "    \n",
    "for item in kiso_dict.items():\n",
    "    print(item[0], \": \", item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/labuser/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-88bd90e540d9>\", line 48, in <module>\n",
      "    ''', re.MULTILINE + re.VERBOSE + re.DOTALL)\n",
      "TypeError: '_sre.SRE_Pattern' object is not callable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/labuser/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1821, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/labuser/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/labuser/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/labuser/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/labuser/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/labuser/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/inspect.py\", line 1415, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/Users/labuser/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 223, in findsource\n",
      "    pat = re.compile(r'^(\\s*def\\s)|(.*(?<!\\w)lambda(:|\\s))|^(\\s*@)')\n",
      "TypeError: '_sre.SRE_Pattern' object is not callable\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'_sre.SRE_Pattern' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import gzip\n",
    "import json\n",
    "import re\n",
    "fname = 'jawiki-country.json.gz'\n",
    "\n",
    "\n",
    "def extract_UK():\n",
    "    '''イギリスに関する記事本文を取得\n",
    "\n",
    "    戻り値：\n",
    "    イギリスの記事本文\n",
    "    '''\n",
    "\n",
    "    with gzip.open(fname, 'rt') as data_file:\n",
    "        for line in data_file:\n",
    "            data_json = json.loads(line)\n",
    "            if data_json['title'] == 'イギリス':\n",
    "                return data_json['text']\n",
    "\n",
    "    raise ValueError('イギリスの記事が見つからない')\n",
    "\n",
    "\n",
    "def remove_markup(target):\n",
    "    '''マークアップの除去\n",
    "    強調マークアップを除去する\n",
    "\n",
    "    引数：\n",
    "    target -- 対象の文字列\n",
    "    戻り値：\n",
    "    マークアップを除去した文字列\n",
    "    '''\n",
    "\n",
    "    # 除去対象の正規表現のコンパイル\n",
    "    pattern = re.compile(r'''\n",
    "        \\'{2,5} # 2〜5個の'\n",
    "        ''', re.MULTILINE + re.VERBOSE)\n",
    "\n",
    "    # 空文字に置換\n",
    "    return pattern.sub('', target)\n",
    "\n",
    "\n",
    "# 基礎情報テンプレートの抽出条件のコンパイル\n",
    "pattern = re.compile(r'''\n",
    "    ^\\{\\{基礎情報.*?$   # '{{基礎情報'で始まる行\n",
    "    (.*?)       # キャプチャ対象、任意の0文字以上、非貪欲\n",
    "    ^\\}\\}$      # '}}'の行\n",
    "    ''', re.MULTILINE + re.VERBOSE + re.DOTALL)\n",
    "\n",
    "# 基礎情報テンプレートの抽出\n",
    "contents = pattern.findall(getEnglandJson())\n",
    "\n",
    "# 抽出結果からのフィールド名と値の抽出条件コンパイル\n",
    "pattern = re.compile(r'''\n",
    "    ^\\|         # '|'で始まる行\n",
    "    (.+?)       # キャプチャ対象（フィールド名）、任意の1文字以上、非貪欲\n",
    "    \\s*         # 空白文字0文字以上\n",
    "    =\n",
    "    \\s*         # 空白文字0文字以上\n",
    "    (.+?)       # キャプチャ対象（値）、任意の1文字以上、非貪欲\n",
    "    (?:         # キャプチャ対象外のグループ開始\n",
    "        (?=\\n\\|)    # 改行+'|'の手前（肯定の先読み）\n",
    "        | (?=\\n$)   # または、改行+終端の手前（肯定の先読み）\n",
    "    )           # グループ終了\n",
    "    ''', re.MULTILINE + re.VERBOSE + re.DOTALL)\n",
    "\n",
    "# フィールド名と値の抽出\n",
    "fields = pattern.findall(contents[0])\n",
    "\n",
    "# 辞書にセット\n",
    "result = {}\n",
    "keys_test = []      # 確認用の出現順フィールド名リスト\n",
    "for field in fields:\n",
    "    result[field[0]] = remove_markup(field[1])\n",
    "    keys_test.append(field[0])\n",
    "\n",
    "# 確認のため表示（確認しやすいようにkeys_testを使ってフィールド名の出現順にソート）\n",
    "for item in sorted(result.items(),\n",
    "        key=lambda field: keys_test.index(field[0])):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### qiitaの答え\n",
    "```\n",
    "# coding: utf-8\n",
    "\n",
    "fname = 'hightemp.txt'\n",
    "count = 0\n",
    "with open(fname) as data_file:\n",
    "    for line in data_file:\n",
    "        count += 1\n",
    "print(count)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 27. 内部リンクの除去"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26の処理に加えて，テンプレートの値からMediaWikiの内部リンクマークアップを除去し，テキストに変換せよ（参考: [マークアップ早見表](http://ja.wikipedia.org/wiki/Help:%E6%97%A9%E8%A6%8B%E8%A1%A8)）．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import re\n",
    "fname = 'jawiki-country.json.gz'\n",
    "\n",
    "\n",
    "def extract_UK():\n",
    "    '''イギリスに関する記事本文を取得\n",
    "\n",
    "    戻り値：\n",
    "    イギリスの記事本文\n",
    "    '''\n",
    "\n",
    "    with gzip.open(fname, 'rt') as data_file:\n",
    "        for line in data_file:\n",
    "            data_json = json.loads(line)\n",
    "            if data_json['title'] == 'イギリス':\n",
    "                return data_json['text']\n",
    "\n",
    "    raise ValueError('イギリスの記事が見つからない')\n",
    "\n",
    "\n",
    "def remove_markup(target):\n",
    "    '''マークアップの除去\n",
    "    強調マークアップと内部リンクを除去する\n",
    "\n",
    "    引数：\n",
    "    target -- 対象の文字列\n",
    "    戻り値：\n",
    "    マークアップを除去した文字列\n",
    "    '''\n",
    "\n",
    "    # 強調マークアップの除去\n",
    "    pattern = re.compile(r'''\n",
    "        (\\'{2,5})   # 2〜5個の'（マークアップの開始）\n",
    "        (.*?)       # 任意の1文字以上（対象の文字列）\n",
    "        (\\1)        # 1番目のキャプチャと同じ（マークアップの終了）\n",
    "        ''', re.MULTILINE + re.VERBOSE)\n",
    "    target = pattern.sub(r'\\2', target)\n",
    "\n",
    "    # 内部リンクの除去\n",
    "    pattern = re.compile(r'''\n",
    "        \\[\\[        # '[['（マークアップの開始）\n",
    "        (?:         # キャプチャ対象外のグループ開始\n",
    "            [^|]*?  # '|'以外の文字が0文字以上、非貪欲\n",
    "            \\|      # '|'\n",
    "        )?          # グループ終了、このグループが0か1出現\n",
    "        ([^|]*?)    # キャプチャ対象、'|'以外が0文字以上、非貪欲（表示対象の文字列）\n",
    "        \\]\\]        # ']]'（マークアップの終了）\n",
    "        ''', re.MULTILINE + re.VERBOSE)\n",
    "    target = pattern.sub(r'\\1', target)\n",
    "\n",
    "    return target\n",
    "\n",
    "\n",
    "# 基礎情報テンプレートの抽出条件のコンパイル\n",
    "pattern = re.compile(r'''\n",
    "    ^\\{\\{基礎情報.*?$   # '{{基礎情報'で始まる行\n",
    "    (.*?)       # キャプチャ対象、任意の0文字以上、非貪欲\n",
    "    ^\\}\\}$      # '}}'の行\n",
    "    ''', re.MULTILINE + re.VERBOSE + re.DOTALL)\n",
    "\n",
    "# 基礎情報テンプレートの抽出\n",
    "contents = pattern.findall(getEnglandJson())\n",
    "\n",
    "# 抽出結果からのフィールド名と値の抽出条件コンパイル\n",
    "pattern = re.compile(r'''\n",
    "    ^\\|         # '|'で始まる行\n",
    "    (.+?)       # キャプチャ対象（フィールド名）、任意の1文字以上、非貪欲\n",
    "    \\s*         # 空白文字0文字以上\n",
    "    =\n",
    "    \\s*         # 空白文字0文字以上\n",
    "    (.+?)       # キャプチャ対象（値）、任意の1文字以上、非貪欲\n",
    "    (?:         # キャプチャ対象外のグループ開始\n",
    "        (?=\\n\\|)    # 改行+'|'の手前（肯定の先読み）\n",
    "        | (?=\\n$)   # または、改行+終端の手前（肯定の先読み）\n",
    "    )           # グループ終了\n",
    "    ''', re.MULTILINE + re.VERBOSE + re.DOTALL)\n",
    "\n",
    "# フィールド名と値の抽出\n",
    "fields = pattern.findall(contents[0])\n",
    "\n",
    "# 辞書にセット\n",
    "result = {}\n",
    "keys_test = []      # 確認用の出現順フィールド名リスト\n",
    "for field in fields:\n",
    "    result[field[0]] = remove_markup(field[1])\n",
    "    keys_test.append(field[0])\n",
    "\n",
    "# 確認のため表示（確認しやすいようにkeys_testを使ってフィールド名の出現順にソート）\n",
    "for item in sorted(result.items(),\n",
    "        key=lambda field: keys_test.index(field[0])):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### qiitaの答え\n",
    "```\n",
    "# coding: utf-8\n",
    "\n",
    "fname = 'hightemp.txt'\n",
    "count = 0\n",
    "with open(fname) as data_file:\n",
    "    for line in data_file:\n",
    "        count += 1\n",
    "print(count)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 28. MediaWikiマークアップの除去"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27の処理に加えて，テンプレートの値からMediaWikiマークアップを可能な限り除去し，国の基本情報を整形せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import re\n",
    "fname = 'jawiki-country.json.gz'\n",
    "\n",
    "\n",
    "def extract_UK():\n",
    "    '''イギリスに関する記事本文を取得\n",
    "\n",
    "    戻り値：\n",
    "    イギリスの記事本文\n",
    "    '''\n",
    "\n",
    "    with gzip.open(fname, 'rt') as data_file:\n",
    "        for line in data_file:\n",
    "            data_json = json.loads(line)\n",
    "            if data_json['title'] == 'イギリス':\n",
    "                return data_json['text']\n",
    "\n",
    "    raise ValueError('イギリスの記事が見つからない')\n",
    "\n",
    "\n",
    "def remove_markup(target):\n",
    "    '''マークアップの除去\n",
    "    MediaWikiマークアップを可能な限り除去する\n",
    "\n",
    "    引数：\n",
    "    target -- 対象の文字列\n",
    "    戻り値：\n",
    "    マークアップを除去した文字列\n",
    "    '''\n",
    "\n",
    "    # 強調マークアップの除去\n",
    "    pattern = re.compile(r'''\n",
    "        (\\'{2,5})   # 2〜5個の'（マークアップの開始）\n",
    "        (.*?)       # 任意の1文字以上（対象の文字列）\n",
    "        (\\1)        # 1番目のキャプチャと同じ（マークアップの終了）\n",
    "        ''', re.MULTILINE + re.VERBOSE)\n",
    "    target = pattern.sub(r'\\2', target)\n",
    "\n",
    "    # 内部リンク、ファイルの除去\n",
    "    pattern = re.compile(r'''\n",
    "        \\[\\[        # '[['（マークアップの開始）\n",
    "        (?:         # キャプチャ対象外のグループ開始\n",
    "            [^|]*?  # '|'以外の文字が0文字以上、非貪欲\n",
    "            \\|      # '|'\n",
    "        )*?         # グループ終了、このグループが0以上出現、非貪欲\n",
    "        ([^|]*?)    # キャプチャ対象、'|'以外が0文字以上、非貪欲（表示対象の文字列）\n",
    "        \\]\\]        # ']]'（マークアップの終了）\n",
    "        ''', re.MULTILINE + re.VERBOSE)\n",
    "    target = pattern.sub(r'\\1', target)\n",
    "\n",
    "    # Template:Langの除去        {{lang|言語タグ|文字列}}\n",
    "    pattern = re.compile(r'''\n",
    "        \\{\\{lang    # '{{lang'（マークアップの開始）\n",
    "        (?:         # キャプチャ対象外のグループ開始\n",
    "            [^|]*?  # '|'以外の文字が0文字以上、非貪欲\n",
    "            \\|      # '|'\n",
    "        )*?         # グループ終了、このグループが0以上出現、非貪欲\n",
    "        ([^|]*?)    # キャプチャ対象、'|'以外が0文字以上、非貪欲（表示対象の文字列）\n",
    "        \\}\\}        # '}}'（マークアップの終了）\n",
    "        ''', re.MULTILINE + re.VERBOSE)\n",
    "    target = pattern.sub(r'\\1', target)\n",
    "\n",
    "    # 外部リンクの除去  [http://xxxx] 、[http://xxx xxx]\n",
    "    pattern = re.compile(r'''\n",
    "        \\[http:\\/\\/ # '[http://'（マークアップの開始）\n",
    "        (?:         # キャプチャ対象外のグループ開始\n",
    "            [^\\s]*? # 空白以外の文字が0文字以上、非貪欲\n",
    "            \\s      # 空白\n",
    "        )?          # グループ終了、このグループが0か1出現\n",
    "        ([^]]*?)    # キャプチャ対象、']'以外が0文字以上、非貪欲（表示対象の文字列）\n",
    "        \\]          # ']'（マークアップの終了）\n",
    "        ''', re.MULTILINE + re.VERBOSE)\n",
    "    target = pattern.sub(r'\\1', target)\n",
    "\n",
    "    # <br>、<ref>の除去\n",
    "    pattern = re.compile(r'''\n",
    "        <           # '<'（マークアップの開始）\n",
    "        \\/?         # '/'が0か1出現（終了タグの場合は/がある）\n",
    "        [br|ref]    # 'br'か'ref'\n",
    "        [^>]*?      # '>'以外が0文字以上、非貪欲\n",
    "        >           # '>'（マークアップの終了）\n",
    "        ''', re.MULTILINE + re.VERBOSE)\n",
    "    target = pattern.sub('', target)\n",
    "\n",
    "    return target\n",
    "\n",
    "\n",
    "# 基礎情報テンプレートの抽出条件のコンパイル\n",
    "pattern = re.compile(r'''\n",
    "    ^\\{\\{基礎情報.*?$   # '{{基礎情報'で始まる行\n",
    "    (.*?)       # キャプチャ対象、任意の0文字以上、非貪欲\n",
    "    ^\\}\\}$      # '}}'の行\n",
    "    ''', re.MULTILINE + re.VERBOSE + re.DOTALL)\n",
    "\n",
    "# 基礎情報テンプレートの抽出\n",
    "contents = pattern.findall(getEnglandJson())\n",
    "\n",
    "# 抽出結果からのフィールド名と値の抽出条件コンパイル\n",
    "pattern = re.compile(r'''\n",
    "    ^\\|         # '|'で始まる行\n",
    "    (.+?)       # キャプチャ対象（フィールド名）、任意の1文字以上、非貪欲\n",
    "    \\s*         # 空白文字0文字以上\n",
    "    =\n",
    "    \\s*         # 空白文字0文字以上\n",
    "    (.+?)       # キャプチャ対象（値）、任意の1文字以上、非貪欲\n",
    "    (?:         # キャプチャ対象外のグループ開始\n",
    "        (?=\\n\\|)    # 改行+'|'の手前（肯定の先読み）\n",
    "        | (?=\\n$)   # または、改行+終端の手前（肯定の先読み）\n",
    "    )           # グループ終了\n",
    "    ''', re.MULTILINE + re.VERBOSE + re.DOTALL)\n",
    "\n",
    "# フィールド名と値の抽出\n",
    "fields = pattern.findall(contents[0])\n",
    "\n",
    "# 辞書にセット\n",
    "result = {}\n",
    "keys_test = []      # 確認用の出現順フィールド名リスト\n",
    "for field in fields:\n",
    "    result[field[0]] = remove_markup(field[1])\n",
    "    keys_test.append(field[0])\n",
    "\n",
    "# 確認のため表示（確認しやすいようにkeys_testを使ってフィールド名の出現順にソート）\n",
    "for item in sorted(result.items(),\n",
    "        key=lambda field: keys_test.index(field[0])):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### qiitaの答え\n",
    "```\n",
    "# coding: utf-8\n",
    "\n",
    "fname = 'hightemp.txt'\n",
    "count = 0\n",
    "with open(fname) as data_file:\n",
    "    for line in data_file:\n",
    "        count += 1\n",
    "print(count)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 29. 国旗画像のURLを取得する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テンプレートの内容を利用し，国旗画像のURLを取得せよ．（ヒント: [MediaWiki](http://www.mediawiki.org/wiki/API:Main_page/ja) APIの[imageinfo](http://www.mediawiki.org/wiki/API:Properties/ja#imageinfo_.2F_ii)を呼び出して，ファイル参照をURLに変換すればよい）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import re\n",
    "import urllib.parse, urllib.request\n",
    "fname = 'jawiki-country.json.gz'\n",
    "\n",
    "\n",
    "def extract_UK():\n",
    "    '''イギリスに関する記事本文を取得\n",
    "\n",
    "    戻り値：\n",
    "    イギリスの記事本文\n",
    "    '''\n",
    "\n",
    "    with gzip.open(fname, 'rt') as data_file:\n",
    "        for line in data_file:\n",
    "            data_json = json.loads(line)\n",
    "            if data_json['title'] == 'イギリス':\n",
    "                return data_json['text']\n",
    "\n",
    "    raise ValueError('イギリスの記事が見つからない')\n",
    "\n",
    "\n",
    "def remove_markup(target):\n",
    "    '''マークアップの除去\n",
    "    MediaWikiマークアップを可能な限り除去する\n",
    "\n",
    "    引数：\n",
    "    target -- 対象の文字列\n",
    "    戻り値：\n",
    "    マークアップを除去した文字列\n",
    "    '''\n",
    "\n",
    "    # 強調マークアップの除去\n",
    "    pattern = re.compile(r'''\n",
    "        (\\'{2,5})   # 2〜5個の'（マークアップの開始）\n",
    "        (.*?)       # 任意の1文字以上（対象の文字列）\n",
    "        (\\1)        # 1番目のキャプチャと同じ（マークアップの終了）\n",
    "        ''', re.MULTILINE + re.VERBOSE)\n",
    "    target = pattern.sub(r'\\2', target)\n",
    "\n",
    "    # 内部リンク、ファイルの除去\n",
    "    pattern = re.compile(r'''\n",
    "        \\[\\[        # '[['（マークアップの開始）\n",
    "        (?:         # キャプチャ対象外のグループ開始\n",
    "            [^|]*?  # '|'以外の文字が0文字以上、非貪欲\n",
    "            \\|      # '|'\n",
    "        )*?         # グループ終了、このグループが0以上出現、非貪欲\n",
    "        ([^|]*?)    # キャプチャ対象、'|'以外が0文字以上、非貪欲（表示対象の文字列）\n",
    "        \\]\\]        # ']]'（マークアップの終了）\n",
    "        ''', re.MULTILINE + re.VERBOSE)\n",
    "    target = pattern.sub(r'\\1', target)\n",
    "\n",
    "    # Template:Langの除去        {{lang|言語タグ|文字列}}\n",
    "    pattern = re.compile(r'''\n",
    "        \\{\\{lang    # '{{lang'（マークアップの開始）\n",
    "        (?:         # キャプチャ対象外のグループ開始\n",
    "            [^|]*?  # '|'以外の文字が0文字以上、非貪欲\n",
    "            \\|      # '|'\n",
    "        )*?         # グループ終了、このグループが0以上出現、非貪欲\n",
    "        ([^|]*?)    # キャプチャ対象、'|'以外が0文字以上、非貪欲（表示対象の文字列）\n",
    "        \\}\\}        # '}}'（マークアップの終了）\n",
    "        ''', re.MULTILINE + re.VERBOSE)\n",
    "    target = pattern.sub(r'\\1', target)\n",
    "\n",
    "    # 外部リンクの除去  [http://xxxx] 、[http://xxx xxx]\n",
    "    pattern = re.compile(r'''\n",
    "        \\[http:\\/\\/ # '[http://'（マークアップの開始）\n",
    "        (?:         # キャプチャ対象外のグループ開始\n",
    "            [^\\s]*? # 空白以外の文字が0文字以上、非貪欲\n",
    "            \\s      # 空白\n",
    "        )?          # グループ終了、このグループが0か1出現\n",
    "        ([^]]*?)    # キャプチャ対象、']'以外が0文字以上、非貪欲（表示対象の文字列）\n",
    "        \\]          # ']'（マークアップの終了）\n",
    "        ''', re.MULTILINE + re.VERBOSE)\n",
    "    target = pattern.sub(r'\\1', target)\n",
    "\n",
    "    # <br>、<ref>の除去\n",
    "    pattern = re.compile(r'''\n",
    "        <           # '<'（マークアップの開始）\n",
    "        \\/?         # '/'が0か1出現（終了タグの場合は/がある）\n",
    "        [br|ref]    # 'br'か'ref'\n",
    "        [^>]*?      # '>'以外が0文字以上、非貪欲\n",
    "        >           # '>'（マークアップの終了）\n",
    "        ''', re.MULTILINE + re.VERBOSE)\n",
    "    target = pattern.sub('', target)\n",
    "\n",
    "    return target\n",
    "\n",
    "\n",
    "# 基礎情報テンプレートの抽出条件のコンパイル\n",
    "pattern = re.compile(r'''\n",
    "    ^\\{\\{基礎情報.*?$   # '{{基礎情報'で始まる行\n",
    "    (.*?)       # キャプチャ対象、任意の0文字以上、非貪欲\n",
    "    ^\\}\\}$      # '}}'の行\n",
    "    ''', re.MULTILINE + re.VERBOSE + re.DOTALL)\n",
    "\n",
    "# 基礎情報テンプレートの抽出\n",
    "contents = pattern.findall(getEnglandJson())\n",
    "\n",
    "# 抽出結果からのフィールド名と値の抽出条件コンパイル\n",
    "pattern = re.compile(r'''\n",
    "    ^\\|         # '|'で始まる行\n",
    "    (.+?)       # キャプチャ対象（フィールド名）、任意の1文字以上、非貪欲\n",
    "    \\s*         # 空白文字0文字以上\n",
    "    =\n",
    "    \\s*         # 空白文字0文字以上\n",
    "    (.+?)       # キャプチャ対象（値）、任意の1文字以上、非貪欲\n",
    "    (?:         # キャプチャ対象外のグループ開始\n",
    "        (?=\\n\\|)    # 改行+'|'の手前（肯定の先読み）\n",
    "        | (?=\\n$)   # または、改行+終端の手前（肯定の先読み）\n",
    "    )           # グループ終了\n",
    "    ''', re.MULTILINE + re.VERBOSE + re.DOTALL)\n",
    "\n",
    "# フィールド名と値の抽出\n",
    "fields = pattern.findall(contents[0])\n",
    "\n",
    "# 辞書にセット\n",
    "result = {}\n",
    "for field in fields:\n",
    "    result[field[0]] = remove_markup(field[1])\n",
    "\n",
    "# 国旗画像の値を取得\n",
    "fname_flag = result['国旗画像']\n",
    "\n",
    "# リクエスト生成\n",
    "url = 'https://www.mediawiki.org/w/api.php?' \\\n",
    "    + 'action=query' \\\n",
    "    + '&titles=File:' + urllib.parse.quote(fname_flag) \\\n",
    "    + '&format=json' \\\n",
    "    + '&prop=imageinfo' \\\n",
    "    + '&iiprop=url'\n",
    "\n",
    "# MediaWikiのサービスへリクエスト送信\n",
    "request = urllib.request.Request(url,\n",
    "    headers={'User-Agent': 'NLP100_Python(@segavvy)'})\n",
    "connection = urllib.request.urlopen(request)\n",
    "\n",
    "# jsonとして受信\n",
    "data = json.loads(connection.read().decode())\n",
    "\n",
    "# URL取り出し\n",
    "url = data['query']['pages'].popitem()[1]['imageinfo'][0]['url']\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### qiitaの答え\n",
    "```\n",
    "# coding: utf-8\n",
    "\n",
    "fname = 'hightemp.txt'\n",
    "count = 0\n",
    "with open(fname) as data_file:\n",
    "    for line in data_file:\n",
    "        count += 1\n",
    "print(count)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
